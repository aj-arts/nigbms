hydra:
  run:
    dir: outputs/poisson1d/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: True

wandb: 
  project: poisson1d
  mode: disabled

data:
  _target_: nigbms.data.data_modules.OfflineDataModule
  data_dir: /home/arisaka/nigbms/data/raw/poisson1d/2024-05-06_06-07-05
  ds_sizes: [100, 100, 100]
  fixed_A: True
  train_rtol: 1.0e-5
  test_rtol: 1.0e-5
  train_maxiter: 1000
  test_maxiter: 1000
  batch_size: 32

meta_solver:
  _target_: nigbms.modules.meta_solvers.MetaSolver
  params_learn: 
    x0: [100]
  features:
    b: [100]
  model:
    _target_: nigbms.modules.models.MLP
    in_dim: 100
    out_dim: 100
    num_layers: 1
    num_neurons: 1024
    hidden_activation: nn.GELU
    output_activation: nn.Identity
    batch_normalization: False
    weight_scale: 0.1

solver:
  _target_: nigbms.modules.solvers.PyTorchJacobi
  params_fix: 
    omega: 1.0
  params_learn: 
    x0: [100]

surrogate:
  _target_: nigbms.modules.surrogates.SurrogateSolver
  params_fix: ${solver.params_fix}
  params_learn: ${solver.params_learn}
  features: 
    b: [100]
    x: [100]
    x0: [100]
    xn: [100]   
  model:
    _target_: nigbms.modules.models.MLP
    in_dim: ${calc_in_dim:${surrogate.features}}
    out_dim: 100
    num_layers: 1
    num_neurons: 1024
    hidden_activation: nn.GELU
    output_activation: nn.Identity
    batch_normalization: False
    weight_scale: 0.1  

wrapper:
  opt:
    _target_: torch.optim.SGD
    lr: 0.001
    momentum: 0.9
  loss:
    _target_: nigbms.modules.losses.SurrogateSolverLoss
    weights:
      dvf_loss: 1
  clip: 100.0
  cfg:
    grad_type: cv_fwd
    jvp_type: forwardAD
    eps: 1.0e-10
    Nv: 2
    v_scale: 1.0
    v_dist: rademacher
  
loss:
  _target_: src.losses.pytorch.SolverIndependentLoss
  weights:
    number_of_iterations_surrogate: 1
  
opt:
  _target_: torch.optim.SGD
  lr: 0.01
sch:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 100
  gamma: 0.1

callbacks:
  - _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val/loss
    patience: 10
    mode: min
    verbose: True
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: epoch
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: val/loss
    mode: min
    save_top_k: 1
    save_last: True

trainer:
  max_epochs: 1000
  gpus: 1
  check_val_every_n_epoch: 1
  log_every_n_steps: 1

seed: 0
monitor: val/loss
test: False
dim: 31