{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd.forward_ad as fwAD\n",
    "\n",
    "primal = torch.randn(10, 10)\n",
    "tangent = torch.randn(10, 10)\n",
    "\n",
    "def fn(x, y):\n",
    "    return x ** 2 + y ** 2\n",
    "\n",
    "# All forward AD computation must be performed in the context of\n",
    "# a ``dual_level`` context. All dual tensors created in such a context\n",
    "# will have their tangents destroyed upon exit. This is to ensure that\n",
    "# if the output or intermediate results of this computation are reused\n",
    "# in a future forward AD computation, their tangents (which are associated\n",
    "# with this computation) won't be confused with tangents from the later\n",
    "# computation.\n",
    "with fwAD.dual_level():\n",
    "    # To create a dual tensor we associate a tensor, which we call the\n",
    "    # primal with another tensor of the same size, which we call the tangent.\n",
    "    # If the layout of the tangent is different from that of the primal,\n",
    "    # The values of the tangent are copied into a new tensor with the same\n",
    "    # metadata as the primal. Otherwise, the tangent itself is used as-is.\n",
    "    #\n",
    "    # It is also important to note that the dual tensor created by\n",
    "    # ``make_dual`` is a view of the primal.\n",
    "    dual_input = fwAD.make_dual(primal, tangent)\n",
    "    assert fwAD.unpack_dual(dual_input).tangent is tangent\n",
    "\n",
    "    # To demonstrate the case where the copy of the tangent happens,\n",
    "    # we pass in a tangent with a layout different from that of the primal\n",
    "    dual_input_alt = fwAD.make_dual(primal, tangent.T)\n",
    "    assert fwAD.unpack_dual(dual_input_alt).tangent is not tangent\n",
    "\n",
    "    # Tensors that do not have an associated tangent are automatically\n",
    "    # considered to have a zero-filled tangent of the same shape.\n",
    "    plain_tensor = torch.randn(10, 10)\n",
    "    dual_output = fn(dual_input, plain_tensor)\n",
    "\n",
    "    # Unpacking the dual returns a ``namedtuple`` with ``primal`` and ``tangent``\n",
    "    # as attributes\n",
    "    jvp = fwAD.unpack_dual(dual_output).tangent\n",
    "\n",
    "assert fwAD.unpack_dual(dual_output).tangent is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "primal = TensorDict({'a': torch.arange(30).reshape(10, 3).float(), 'b': torch.ones(10, 4, 5)}, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tangent = TensorDict({'a': torch.ones(10, 3), 'b': torch.ones(10, 4, 5)}, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dict(x):\n",
    "    return x['a'] ** 2 + x['b'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 200.,  201.,  204.],\n",
       "         [ 209.,  216.,  225.],\n",
       "         [ 236.,  249.,  264.],\n",
       "         [ 281.,  300.,  321.],\n",
       "         [ 344.,  369.,  396.],\n",
       "         [ 425.,  456.,  489.],\n",
       "         [ 524.,  561.,  600.],\n",
       "         [ 641.,  684.,  729.],\n",
       "         [ 776.,  825.,  876.],\n",
       "         [ 929.,  984., 1041.]]),\n",
       " tensor([[200., 202., 204.],\n",
       "         [206., 208., 210.],\n",
       "         [212., 214., 216.],\n",
       "         [218., 220., 222.],\n",
       "         [224., 226., 228.],\n",
       "         [230., 232., 234.],\n",
       "         [236., 238., 240.],\n",
       "         [242., 244., 246.],\n",
       "         [248., 250., 252.],\n",
       "         [254., 256., 258.]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.func.jvp(f_dict, (primal,), (tangent,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'TensorDict' and 'TensorDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m tensordict2 \u001b[38;5;241m=\u001b[39m TensorDict({\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey1\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey2\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     13\u001b[0m }, batch_size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 2つのtensordictを足す\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtensordict1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensordict2\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 結果を確認\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'TensorDict' and 'TensorDict'"
     ]
    }
   ],
   "source": [
    "from tensordict import TensorDict\n",
    "import torch\n",
    "\n",
    "# 2つのtensordictを作成\n",
    "tensordict1 = TensorDict({\n",
    "    \"key1\": torch.randn(3, 4),\n",
    "    \"key2\": torch.randn(3, 4)\n",
    "}, batch_size=[3])\n",
    "\n",
    "tensordict2 = TensorDict({\n",
    "    \"key1\": torch.randn(3, 4),\n",
    "    \"key2\": torch.randn(3, 4)\n",
    "}, batch_size=[3])\n",
    "\n",
    "# 2つのtensordictを足す\n",
    "result = tensordict1 + tensordict2\n",
    "\n",
    "# 結果を確認\n",
    "print(result[\"key1\"])\n",
    "print(result[\"key2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'TensorDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensordict1\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'TensorDict'"
     ]
    }
   ],
   "source": [
    "1.0 * tensordict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensordict._td.TensorDict"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensordict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        key1: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        key2: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([3]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict1.apply(lambda x: 2 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0484, -1.8561,  1.4272,  1.0533],\n",
       "        [-1.5890,  0.2027, -0.1566,  1.5146],\n",
       "        [ 1.2385,  2.0889,  1.0955, -1.2020]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict1.apply(lambda x: 2 * x)[\"key2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5242, -0.9280,  0.7136,  0.5267],\n",
       "        [-0.7945,  0.1013, -0.0783,  0.7573],\n",
       "        [ 0.6193,  1.0444,  0.5478, -0.6010]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict1['key2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tensordicts(tensordict1, tensordict2):\n",
    "    \"\"\"\n",
    "    2つのtensordictを足し合わせる関数\n",
    "    \n",
    "    Args:\n",
    "        tensordict1 (TensorDict): 1つ目のtensordict\n",
    "        tensordict2 (TensorDict): 2つ目のtensordict\n",
    "        \n",
    "    Returns:\n",
    "        TensorDict: 2つのtensordictを足し合わせた結果\n",
    "    \"\"\"\n",
    "    # 2つのtensordictのキーが同じであることを確認\n",
    "    assert set(tensordict1.keys()) == set(tensordict2.keys()), \"Keys in the two tensordicts must be the same.\"\n",
    "    \n",
    "    # 各keyに対応するtensorを足し合わせる\n",
    "    result = {k:tensordict1[k] + tensordict2[k] for k in tensordict1.keys()}\n",
    "    \n",
    "    # 新しいtensordictを作成して返す\n",
    "    return TensorDict(result, batch_size=tensordict1.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3702,  0.1352,  0.4325,  1.0031],\n",
       "        [-1.2659, -1.4851,  0.7063, -0.8183],\n",
       "        [ 0.7257,  0.3506,  0.5705, -0.2927]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_tensordicts(tensordict1, tensordict2)[\"key2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3702,  0.1352,  0.4325,  1.0031],\n",
       "        [-1.2659, -1.4851,  0.7063, -0.8183],\n",
       "        [ 0.7257,  0.3506,  0.5705, -0.2927]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict1[\"key2\"] + tensordict2[\"key2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(tensordict1, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from nigbms.utils.solver import rademacher_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1713701388.815420] [bae72f51ae96:24547:0]     ucp_context.c:1774 UCX  WARN  UCP version is incompatible, required: 1.16, actual: 1.12 (release 1)\n",
      "[1713701388.829896] [bae72f51ae96:24547:0]     ucp_context.c:1774 UCX  WARN  UCP version is incompatible, required: 1.16, actual: 1.12 (release 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sohei/.local/lib/python3.10/site-packages/tensordict/_pytree.py:147: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from petsc4py import PETSc\n",
    "from tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict = TensorDict({'a': torch.arange(30).reshape(10, 3).float(), 'b': torch.ones(10, 2, 5)}, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x['a'].sum() + x['b'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "scalar tensor expected to be 0 dim but it has 2 dimensions and 10 elements.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtensordict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensordict/base.py:4721\u001b[0m, in \u001b[0;36mTensorDictBase.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: TensorDictBase \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m-> 4721\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensordict/base.py:5339\u001b[0m, in \u001b[0;36mTensorDictBase.mul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5338\u001b[0m     other_val \u001b[38;5;241m=\u001b[39m other\n\u001b[0;32m-> 5339\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5340\u001b[0m items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, vals))\n\u001b[1;32m   5341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_apply(\n\u001b[1;32m   5342\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m name, val: items[name],\n\u001b[1;32m   5343\u001b[0m     named\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   5344\u001b[0m     nested_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   5345\u001b[0m     is_leaf\u001b[38;5;241m=\u001b[39m_NESTED_TENSORS_AS_LISTS,\n\u001b[1;32m   5346\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: scalar tensor expected to be 0 dim but it has 2 dimensions and 10 elements."
     ]
    }
   ],
   "source": [
    "tensordict * b.reshape(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = f(tensordict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(10) * 2\n",
    "b = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1000, 0.2000],\n",
       "        [0.3000, 0.4000, 0.5000],\n",
       "        [0.6000, 0.7000, 0.8000],\n",
       "        [0.9000, 1.0000, 1.1000],\n",
       "        [1.2000, 1.3000, 1.4000],\n",
       "        [1.5000, 1.6000, 1.7000],\n",
       "        [1.8000, 1.9000, 2.0000],\n",
       "        [2.1000, 2.2000, 2.3000],\n",
       "        [2.4000, 2.5000, 2.6000],\n",
       "        [2.7000, 2.8000, 2.9000]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tensordict * 0.1)[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.],\n",
       "        [12., 13., 14.],\n",
       "        [15., 16., 17.],\n",
       "        [18., 19., 20.],\n",
       "        [21., 22., 23.],\n",
       "        [24., 25., 26.],\n",
       "        [27., 28., 29.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtensordict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensordict/base.py:4256\u001b[0m, in \u001b[0;36mTensorDictBase.apply\u001b[0;34m(self, fn, batch_size, device, names, inplace, default, filter_empty, *others, **constructor_kwargs)\u001b[0m\n\u001b[1;32m   4163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4164\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4165\u001b[0m     fn: Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4173\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconstructor_kwargs,\n\u001b[1;32m   4174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies a callable to all values stored in the tensordict and sets them in a new tensordict.\u001b[39;00m\n\u001b[1;32m   4176\u001b[0m \n\u001b[1;32m   4177\u001b[0m \u001b[38;5;124;03m    The callable signature must be ``Callable[Tuple[Tensor, ...], Optional[Union[Tensor, TensorDictBase]]]``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4254\u001b[0m \n\u001b[1;32m   4255\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_nest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4258\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mothers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4262\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4266\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconstructor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4267\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensordict/_td.py:906\u001b[0m, in \u001b[0;36mTensorDict._apply_nest\u001b[0;34m(self, fn, batch_size, device, names, inplace, checked, call_on_nested, default, named, nested_keys, prefix, filter_empty, is_leaf, *others, **constructor_kwargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m             item_trsf \u001b[38;5;241m=\u001b[39m fn(key, item, \u001b[38;5;241m*\u001b[39m_others)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 906\u001b[0m         item_trsf \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_others\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item_trsf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m any_set:\n",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tensordict\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "tensordict.apply(lambda x: x * a)[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def multiply_tensor(tensor1, tensor2):\n",
    "    \"\"\"\n",
    "    (N, 1)のtensorを(N, a_1, a_2, ..., a_n)のtensorに乗算する関数\n",
    "    \n",
    "    Args:\n",
    "        tensor1 (torch.Tensor): (N,)のtensor\n",
    "        tensor2 (torch.Tensor): (N, a_1, a_2, ..., a_n)のtensor\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: (N, a_1, a_2, ..., a_n)のtensor\n",
    "    \"\"\"\n",
    "    # tensor1を適切な形状に変形する\n",
    "    for _ in range(tensor2.ndim - 1):\n",
    "        tensor1 = tensor1.unsqueeze(-1)\n",
    "    \n",
    "    # 乗算を実行\n",
    "    result = tensor1 * tensor2\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 入力データの例\n",
    "tensor1 = torch.randn(10, 1)\n",
    "tensor2 = torch.randn(10, 5, 3)\n",
    "\n",
    "# 関数を呼び出して結果を取得\n",
    "result = multiply_tensor(tensor1, tensor2)\n",
    "print(result.shape)  # Output: torch.Size([10, 5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# 入力Tensor\n",
    "a = torch.randn(10)\n",
    "b = torch.randn(10, 3, 4, 5)\n",
    "\n",
    "# Aをreshape\n",
    "a_reshaped = reshape_a_to_b(a, b)\n",
    "print(a_reshaped.size())  # torch.Size([10, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  1,  1,  1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
